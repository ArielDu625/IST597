{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IST597-Assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9rOiQPuwLCL"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Yvj0wq52FfKH",
        "outputId": "1f737355-2cfb-4e2f-bb07-064796056ee9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### define BN layer for MLP"
      ],
      "metadata": {
        "id": "U1eEzs6IWc9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BNLayer(keras.layers.Layer):\n",
        "    def __init__(self, dim, epsilon=10e-8, momentum=0.99):\n",
        "        super(BNLayer, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "        self.momentum = momentum\n",
        "        self.dim = dim\n",
        "\n",
        "        self.it_call = 0\n",
        "        self.batch_size = 0\n",
        "\n",
        "        self.mu = self.add_weight(\"mu\", shape=[self.dim,], \n",
        "                                initializer=\"zeros\",\n",
        "                                trainable=False)\n",
        "        self.var = self.add_weight(\"var\", shape=[self.dim,], \n",
        "                                   initializer=\"zeros\",\n",
        "                                   trainable=False)\n",
        "\n",
        "        self.gamma = self.add_weight(\"gamma\", shape=[1, self.dim],\n",
        "                                     initializer=\"random_normal\",\n",
        "                                     trainable=True)\n",
        "        self.beta = self.add_weight(\"beta\", shape=[1, self.dim],\n",
        "                                    initializer=\"random_normal\",\n",
        "                                    trainable=True)\n",
        "        \n",
        "    \n",
        "    def call(self, inputs, training=True):\n",
        "        \"\"\"forward\n",
        "        BN(x) = gamma * ((x - mu) / sqrt(var + epsilon)) + beta\n",
        "        \"\"\"\n",
        "\n",
        "        self.it_call += 1\n",
        "\n",
        "        if training:\n",
        "            if self.batch_size == 0:\n",
        "                self.batch_size = inputs.shape[0]\n",
        "            \n",
        "            # training: compute BN \n",
        "            batch_mu = tf.math.reduce_mean(inputs, axis=0)\n",
        "            batch_var = tf.math.reduce_variance(inputs, axis=0)\n",
        "            \n",
        "            normalized_inputs = tf.math.divide((inputs - batch_mu), tf.math.sqrt(batch_var + self.epsilon))\n",
        "            bn_inputs = tf.math.multiply(self.gamma, normalized_inputs) + self.beta\n",
        "\n",
        "            # update mu and var\n",
        "            if inputs.shape[0] == self.batch_size:\n",
        "                running_mu = batch_mu\n",
        "                running_var = batch_var\n",
        "            else:\n",
        "                # the last batch in training may have sample less than batch size\n",
        "                running_mu = batch_mu / inputs.shape[0] * self.batch_size\n",
        "                running_mu = batch_var / inputs.shape[0] * self.batch_size\n",
        "            \n",
        "            cur_mu = running_mu * (self.momentum / self.it_call) + self.mu * (1 - (self.momentum/self.it_call))\n",
        "            self.mu.assign(cur_mu)\n",
        "            cur_var = running_var * (self.momentum / self.it_call) + self.var * (1 - (self.momentum/self.it_call))\n",
        "            self.var.assign(cur_var)\n",
        "\n",
        "\n",
        "        else:\n",
        "            normalized_inputs = tf.math.divide((inputs - self.mu), tf.math.sqrt(self.var + self.epsilon))\n",
        "            bn_inputs = tf.math.multiply(self.gamma, normalized_inputs) + self.beta\n",
        "        \n",
        "        return bn_inputs\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "lfchES4-WgBM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### define MLP"
      ],
      "metadata": {
        "id": "QsRZmbg4t-vG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(tf.keras.Model):\n",
        "    def __init__(self, input_size, output_size, hidden_size,\n",
        "                 before_activation_bn=True):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.before_activation_bn = before_activation_bn\n",
        "\n",
        "        self.input_layer = keras.layers.Dense(hidden_size, activation=None)\n",
        "        self.hidden1 = keras.layers.Dense(hidden_size, activation=None)\n",
        "        self.bn1 = BNLayer(hidden_size)\n",
        "        self.hidden2 = keras.layers.Dense(hidden_size, activation=None)\n",
        "        self.bn2 = BNLayer(hidden_size)\n",
        "        self.output_layer = keras.layers.Dense(output_size, activation=None)\n",
        "        \n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        x = tf.cast(inputs, dtype=tf.float32)\n",
        "        x = self.input_layer(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "\n",
        "        if self.before_activation_bn:\n",
        "            x = self.hidden1(x)\n",
        "            x = self.bn1(x, training=training)\n",
        "            x = tf.nn.relu(x)\n",
        "            x = self.hidden2(x)\n",
        "            x = self.bn2(x, training=training)\n",
        "            x = tf.nn.relu(x)\n",
        "        else:\n",
        "            x = self.hidden1(x)\n",
        "            x = tf.nn.relu(x)\n",
        "            x = self.bn1(x, training=training)\n",
        "            x = self.hidden2(x)\n",
        "            x = tf.nn.relu(x)\n",
        "            x = self.bn2(x, training=training)\n",
        "        \n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "    "
      ],
      "metadata": {
        "id": "inaomPeaUAiI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report performance of MLP model"
      ],
      "metadata": {
        "id": "PeN0jz79xPEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "x_train = tf.reshape(x_train, (x_train.shape[0], -1))\n",
        "x_test = tf.reshape(x_test, (x_test.shape[0], -1))\n",
        "\n",
        "x_val = x_train[50000:60000]\n",
        "x_train = x_train[0:50000]\n",
        "y_val = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOsq8AJAVn8a",
        "outputId": "ccc65808-a391-402e-ed87-147a227eabd5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 784)\n",
            "(50000,)\n",
            "(10000, 784)\n",
            "(10000,)\n",
            "(10000, 784)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### apply BN after pre-activation: g(BN(f(x)))"
      ],
      "metadata": {
        "id": "G5uQp-w7TiUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 28 * 28\n",
        "output_size = 10\n",
        "hidden_size = 1024\n",
        "before_activation_bn = True\n",
        "\n",
        "accuracy = []\n",
        "for i in range(3):\n",
        "    tf.random.set_seed(i + 12)\n",
        "    model = MLP(input_size, output_size, hidden_size, before_activation_bn=before_activation_bn)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    acc = keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n",
        "\n",
        "    model.compile(optimizer, loss=loss_fn, metrics=[acc])\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "    history = model.fit(x_train, y_train, epochs=20, batch_size=128,\n",
        "              validation_data=(x_val, y_val),\n",
        "              callbacks=[callback])\n",
        "\n",
        "    _, test_accuracy = model.evaluate(x_test, y_test, batch_size=len(x_test))\n",
        "    accuracy.append(test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeOesJdjVJDV",
        "outputId": "f1897254-c7a7-4083-9fc9-94942d92676a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "391/391 [==============================] - 8s 14ms/step - loss: 1.0788 - acc: 0.8043 - val_loss: 0.5340 - val_acc: 0.8590\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4153 - acc: 0.8752 - val_loss: 0.3652 - val_acc: 0.8780\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3146 - acc: 0.8936 - val_loss: 0.3234 - val_acc: 0.8858\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2704 - acc: 0.9048 - val_loss: 0.3056 - val_acc: 0.8878\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2399 - acc: 0.9149 - val_loss: 0.3063 - val_acc: 0.8868\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2134 - acc: 0.9240 - val_loss: 0.3035 - val_acc: 0.8900\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1914 - acc: 0.9311 - val_loss: 0.2930 - val_acc: 0.8918\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.1696 - acc: 0.9401 - val_loss: 0.2976 - val_acc: 0.8951\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1511 - acc: 0.9460 - val_loss: 0.3224 - val_acc: 0.8882\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1372 - acc: 0.9510 - val_loss: 0.3068 - val_acc: 0.8962\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.3303 - acc: 0.8926\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 8s 16ms/step - loss: 1.0872 - acc: 0.8004 - val_loss: 0.5367 - val_acc: 0.8580\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.4207 - acc: 0.8726 - val_loss: 0.3696 - val_acc: 0.8748\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 0.3199 - acc: 0.8914 - val_loss: 0.3258 - val_acc: 0.8873\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 0.2738 - acc: 0.9035 - val_loss: 0.3104 - val_acc: 0.8874\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.2428 - acc: 0.9126 - val_loss: 0.2976 - val_acc: 0.8925\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2171 - acc: 0.9235 - val_loss: 0.2992 - val_acc: 0.8914\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1950 - acc: 0.9294 - val_loss: 0.3096 - val_acc: 0.8905\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.1746 - acc: 0.9369 - val_loss: 0.3041 - val_acc: 0.8905\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.3284 - acc: 0.8868\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 6s 11ms/step - loss: 1.0744 - acc: 0.7961 - val_loss: 0.5449 - val_acc: 0.8553\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4181 - acc: 0.8743 - val_loss: 0.3742 - val_acc: 0.8746\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3165 - acc: 0.8926 - val_loss: 0.3237 - val_acc: 0.8837\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.2728 - acc: 0.9047 - val_loss: 0.3111 - val_acc: 0.8876\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.2401 - acc: 0.9144 - val_loss: 0.3180 - val_acc: 0.8835\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.2134 - acc: 0.9235 - val_loss: 0.2894 - val_acc: 0.8972\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.1899 - acc: 0.9317 - val_loss: 0.3063 - val_acc: 0.8908\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.1732 - acc: 0.9393 - val_loss: 0.2910 - val_acc: 0.8964\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.1545 - acc: 0.9444 - val_loss: 0.3046 - val_acc: 0.8937\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 0.3303 - acc: 0.8909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(accuracy)\n",
        "var = np.var(accuracy)\n",
        "print(f\"the mean of 3 runs is {mean}, and the variance is {var}\")\n",
        "\n",
        "plt.boxplot(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "Nw_X-b3l4RvR",
        "outputId": "17ab156b-729c-486b-d40b-84ea20f8dc2d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean of 3 runs is 0.8901000022888184, and the variance is 5.926694463198601e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boxes': [<matplotlib.lines.Line2D at 0x7fd3acff5090>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7fd3acf7add0>,\n",
              "  <matplotlib.lines.Line2D at 0x7fd3acee9d50>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7fd3acee0950>],\n",
              " 'means': [],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7fd3acee0cd0>],\n",
              " 'whiskers': [<matplotlib.lines.Line2D at 0x7fd3aceade50>,\n",
              "  <matplotlib.lines.Line2D at 0x7fd4281e5110>]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### apply BN after post_activation: BN(g(f(x)))"
      ],
      "metadata": {
        "id": "lIDBHwl6Vx_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 28 * 28\n",
        "output_size = 10\n",
        "hidden_size = 1024\n",
        "before_activation_bn = False\n",
        "\n",
        "accuracy = []\n",
        "for i in range(3):\n",
        "    tf.random.set_seed(i + 10)\n",
        "    model = MLP(input_size, output_size, hidden_size, before_activation_bn=before_activation_bn)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    acc = keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n",
        "\n",
        "    model.compile(optimizer, loss=loss_fn, metrics=[acc])\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "    history = model.fit(x_train, y_train, epochs=20, batch_size=128,\n",
        "              validation_data=(x_val, y_val),\n",
        "              callbacks=[callback])\n",
        "\n",
        "    _, test_accuracy = model.evaluate(x_test, y_test, batch_size=len(x_test))\n",
        "    accuracy.append(test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nfcbh1bV5lT",
        "outputId": "9bc7d870-c150-46b4-9611-a832257a23ca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "391/391 [==============================] - 6s 11ms/step - loss: 0.9098 - acc: 0.8046 - val_loss: 0.4968 - val_acc: 0.8585\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3955 - acc: 0.8734 - val_loss: 0.3752 - val_acc: 0.8698\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3233 - acc: 0.8885 - val_loss: 0.3464 - val_acc: 0.8792\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.2886 - acc: 0.8982 - val_loss: 0.3448 - val_acc: 0.8837\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.2645 - acc: 0.9044 - val_loss: 0.3365 - val_acc: 0.8815\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.2465 - acc: 0.9110 - val_loss: 0.3195 - val_acc: 0.8836\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.2297 - acc: 0.9159 - val_loss: 0.3414 - val_acc: 0.8853\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.2130 - acc: 0.9216 - val_loss: 0.3714 - val_acc: 0.8793\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2095 - acc: 0.9231 - val_loss: 0.3415 - val_acc: 0.8857\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.3900 - acc: 0.8774\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 5s 11ms/step - loss: 0.9103 - acc: 0.8040 - val_loss: 0.4754 - val_acc: 0.8582\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3956 - acc: 0.8739 - val_loss: 0.3741 - val_acc: 0.8751\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3257 - acc: 0.8870 - val_loss: 0.3644 - val_acc: 0.8732\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2924 - acc: 0.8956 - val_loss: 0.3428 - val_acc: 0.8810\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2664 - acc: 0.9034 - val_loss: 0.3531 - val_acc: 0.8850\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.2527 - acc: 0.9069 - val_loss: 0.3509 - val_acc: 0.8866\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2344 - acc: 0.9142 - val_loss: 0.3900 - val_acc: 0.8813\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.4043 - acc: 0.8773\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 5s 11ms/step - loss: 0.9026 - acc: 0.8063 - val_loss: 0.4813 - val_acc: 0.8620\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3934 - acc: 0.8737 - val_loss: 0.3846 - val_acc: 0.8740\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3224 - acc: 0.8891 - val_loss: 0.3430 - val_acc: 0.8791\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2879 - acc: 0.8973 - val_loss: 0.3348 - val_acc: 0.8797\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2669 - acc: 0.9041 - val_loss: 0.3330 - val_acc: 0.8839\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.2448 - acc: 0.9104 - val_loss: 0.3317 - val_acc: 0.8840\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.2294 - acc: 0.9163 - val_loss: 0.3268 - val_acc: 0.8866\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2122 - acc: 0.9231 - val_loss: 0.3124 - val_acc: 0.8932\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.2009 - acc: 0.9247 - val_loss: 0.3803 - val_acc: 0.8837\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1861 - acc: 0.9318 - val_loss: 0.3338 - val_acc: 0.8929\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1804 - acc: 0.9331 - val_loss: 0.3557 - val_acc: 0.8878\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.3833 - acc: 0.8806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(accuracy)\n",
        "var = np.var(accuracy)\n",
        "print(f\"the mean of 3 runs is {mean}, and the variance is {var}\")\n",
        "\n",
        "plt.boxplot(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "Kleywo2YWfAo",
        "outputId": "ec9d118f-309f-4baf-8759-8845c42358c6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean of 3 runs is 0.8784333268801371, and the variance is 2.3488485404578164e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boxes': [<matplotlib.lines.Line2D at 0x7fd3ae661e10>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7fd3ae669e90>,\n",
              "  <matplotlib.lines.Line2D at 0x7fd3ae66f410>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7fd3ae66fed0>],\n",
              " 'means': [],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7fd3ae66f990>],\n",
              " 'whiskers': [<matplotlib.lines.Line2D at 0x7fd3ad0da290>,\n",
              "  <matplotlib.lines.Line2D at 0x7fd3ae669950>]}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### define BN layer for CNN"
      ],
      "metadata": {
        "id": "Z_FhZ-6jXPpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BNLayer(keras.layers.Layer):\n",
        "    def __init__(self, dim, epsilon=10e-8, momentum=0.99):\n",
        "        super(BNLayer, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "        self.momentum = momentum\n",
        "        self.dim = dim\n",
        "\n",
        "        self.it_call = 0\n",
        "        self.batch_size = 0\n",
        "\n",
        "        self.mu = self.add_weight(\"mu\", shape=[self.dim,], \n",
        "                                initializer=\"zeros\",\n",
        "                                trainable=False)\n",
        "        self.var = self.add_weight(\"var\", shape=[self.dim,], \n",
        "                                   initializer=\"zeros\",\n",
        "                                   trainable=False)\n",
        "\n",
        "        self.gamma = self.add_weight(\"gamma\", shape=[1, self.dim],\n",
        "                                     initializer=\"random_normal\",\n",
        "                                     trainable=True)\n",
        "        self.beta = self.add_weight(\"beta\", shape=[1, self.dim],\n",
        "                                    initializer=\"random_normal\",\n",
        "                                    trainable=True)\n",
        "        \n",
        "    \n",
        "    def call(self, inputs, training=True):\n",
        "        \"\"\"forward\n",
        "        BN(x) = gamma * ((x - mu) / sqrt(var + epsilon)) + beta\n",
        "        \"\"\"\n",
        "\n",
        "        self.it_call += 1\n",
        "\n",
        "        if training:\n",
        "            if self.batch_size == 0:\n",
        "                self.batch_size = inputs.shape[0]\n",
        "            \n",
        "            # training: compute BN \n",
        "            batch_mu = tf.math.reduce_mean(inputs, axis=(0,1,2))\n",
        "            batch_var = tf.math.reduce_variance(inputs, axis=(0,1,2))\n",
        "            \n",
        "            normalized_inputs = tf.math.divide((inputs - batch_mu), tf.math.sqrt(batch_var + self.epsilon))\n",
        "            bn_inputs = tf.math.multiply(self.gamma, normalized_inputs) + self.beta\n",
        "\n",
        "            # update mu and var\n",
        "            if inputs.shape[0] == self.batch_size:\n",
        "                running_mu = batch_mu\n",
        "                running_var = batch_var\n",
        "            else:\n",
        "                # the last batch in training may have sample less than batch size\n",
        "                running_mu = batch_mu / inputs.shape[0] * self.batch_size\n",
        "                running_mu = batch_var / inputs.shape[0] * self.batch_size\n",
        "            \n",
        "            cur_mu = running_mu * (self.momentum / self.it_call) + self.mu * (1 - (self.momentum/self.it_call))\n",
        "            self.mu.assign(cur_mu)\n",
        "            cur_var = running_var * (self.momentum / self.it_call) + self.var * (1 - (self.momentum/self.it_call))\n",
        "            self.var.assign(cur_var)\n",
        "\n",
        "\n",
        "        else:\n",
        "            normalized_inputs = tf.math.divide((inputs - self.mu), tf.math.sqrt(self.var + self.epsilon))\n",
        "            bn_inputs = tf.math.multiply(self.gamma, normalized_inputs) + self.beta\n",
        "        \n",
        "        return bn_inputs"
      ],
      "metadata": {
        "id": "eaIWoKg3XXHM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### define CNN"
      ],
      "metadata": {
        "id": "SydaG0gpXZZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageRecognitionCNN(tf.keras.Model):\n",
        "    def __init__(self, num_classes,\n",
        "                 filter=64,\n",
        "                 kernel=3, \n",
        "                 before_activation_bn=True):\n",
        "        super(ImageRecognitionCNN, self).__init__()\n",
        "        self.filter=64\n",
        "        self.kernel=3\n",
        "        self.before_activation_bn = before_activation_bn\n",
        "\n",
        "        # Initialize layers\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filter, kernel, padding='same', activation=None)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filter, kernel, padding='same', activation=None)\n",
        "        self.bn1 = BNLayer(filter)\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filter, kernel, padding='same', activation=None)\n",
        "        self.bn2 = BNLayer(filter)\n",
        "        self.conv4 = tf.keras.layers.Conv2D(filter, kernel, padding='same', activation=None)\n",
        "        self.bn3 = BNLayer(filter)\n",
        "        self.conv8 = tf.keras.layers.Conv2D(num_classes, 1, padding='same', activation=None)\n",
        "    \n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        x = self.conv1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        if self.before_activation_bn:\n",
        "            x = self.conv2(x)\n",
        "            x = self.bn1(x)\n",
        "            x = tf.nn.relu(x)\n",
        "            x = self.pool1(x)\n",
        "\n",
        "            x = self.conv3(x)\n",
        "            x = self.bn2(x)\n",
        "            x = tf.nn.relu(x)\n",
        "            x = self.pool1(x)\n",
        "\n",
        "            x = self.conv4(x)\n",
        "            x = self.bn3(x)\n",
        "            x = tf.nn.relu(x)\n",
        "            x = self.pool1(x)\n",
        "            x = self.conv8(x)\n",
        "        else:\n",
        "            x = self.conv2(x)\n",
        "            x = tf.nn.relu(x)\n",
        "            x = self.bn1(x)\n",
        "            x = self.pool1(x)\n",
        "\n",
        "            x = self.conv3(x)\n",
        "            x = tf.nn.relu(x)\n",
        "            x = self.bn2(x)\n",
        "            x = self.pool1(x)\n",
        "\n",
        "            x = self.conv4(x)\n",
        "            x = tf.nn.relu(x)\n",
        "            x = self.bn3(x)\n",
        "            x = self.pool1(x)\n",
        "            x = self.conv8(x)\n",
        "        \n",
        "        x = tf.reshape(x, (-1, 10))\n",
        "        return x\n",
        "        "
      ],
      "metadata": {
        "id": "m-qsgkB0Xa-c"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report performance of CNN model"
      ],
      "metadata": {
        "id": "Ic6g-ikAxmzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32').reshape(-1,28,28,1) / 255\n",
        "x_test = x_test.astype('float32').reshape(-1,28,28,1) / 255\n",
        "\n",
        "x_val = x_train[50000:60000]\n",
        "x_train = x_train[0:50000]\n",
        "\n",
        "y_val = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nIb1--vqxuS",
        "outputId": "368bbffa-400a-4405-f95d-e537bff2cbe5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 28, 28, 1)\n",
            "(50000,)\n",
            "(10000, 28, 28, 1)\n",
            "(10000,)\n",
            "(10000, 28, 28, 1)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### apply BN after pre-activation: g(BN(f(x)))"
      ],
      "metadata": {
        "id": "BHMgiXgbXbf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "filter=64\n",
        "kernel=3 \n",
        "before_activation_bn = True\n",
        "\n",
        "accuracy = []\n",
        "for i in range(3):\n",
        "    tf.random.set_seed(i + 12)\n",
        "    model = ImageRecognitionCNN(num_classes, \n",
        "                                filter=filter,\n",
        "                                kernel=kernel, \n",
        "                                before_activation_bn=before_activation_bn)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    acc = keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n",
        "\n",
        "    model.compile(optimizer, loss=loss_fn, metrics=[acc])\n",
        "    callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "    history = model.fit(x_train, y_train, epochs=50, batch_size=128,\n",
        "              validation_data=(x_val, y_val),\n",
        "              callbacks=[callback])\n",
        "\n",
        "    _, test_accuracy = model.evaluate(x_test, y_test, batch_size=len(x_test))\n",
        "    accuracy.append(test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1bWXAolqhIg",
        "outputId": "c9a9a059-15b0-4259-ee16-e6bccdd5710b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "391/391 [==============================] - 14s 28ms/step - loss: 1.7471 - acc: 0.6469 - val_loss: 1.2436 - val_acc: 0.7794\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 12s 31ms/step - loss: 0.9362 - acc: 0.8097 - val_loss: 0.6971 - val_acc: 0.8335\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 11s 29ms/step - loss: 0.5821 - acc: 0.8534 - val_loss: 0.4907 - val_acc: 0.8663\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.4265 - acc: 0.8798 - val_loss: 0.3920 - val_acc: 0.8825\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.3475 - acc: 0.8945 - val_loss: 0.3351 - val_acc: 0.8903\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2993 - acc: 0.9045 - val_loss: 0.3022 - val_acc: 0.9016\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2686 - acc: 0.9123 - val_loss: 0.2769 - val_acc: 0.9065\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2456 - acc: 0.9184 - val_loss: 0.2735 - val_acc: 0.9054\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.2283 - acc: 0.9231 - val_loss: 0.2519 - val_acc: 0.9120\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2135 - acc: 0.9275 - val_loss: 0.2486 - val_acc: 0.9117\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.2017 - acc: 0.9313 - val_loss: 0.2404 - val_acc: 0.9154\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.1889 - acc: 0.9358 - val_loss: 0.2384 - val_acc: 0.9176\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1797 - acc: 0.9386 - val_loss: 0.2437 - val_acc: 0.9097\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1696 - acc: 0.9417 - val_loss: 0.2304 - val_acc: 0.9165\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.1621 - acc: 0.9442 - val_loss: 0.2246 - val_acc: 0.9220\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.1513 - acc: 0.9499 - val_loss: 0.2417 - val_acc: 0.9138\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.1452 - acc: 0.9510 - val_loss: 0.2227 - val_acc: 0.9208\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1372 - acc: 0.9542 - val_loss: 0.2231 - val_acc: 0.9213\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.1302 - acc: 0.9564 - val_loss: 0.2326 - val_acc: 0.9182\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.1241 - acc: 0.9597 - val_loss: 0.2230 - val_acc: 0.9204\n",
            "1/1 [==============================] - 1s 533ms/step - loss: 0.2412 - acc: 0.9158\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 12s 27ms/step - loss: 1.7796 - acc: 0.6083 - val_loss: 1.3109 - val_acc: 0.7833\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 1.0014 - acc: 0.8203 - val_loss: 0.7481 - val_acc: 0.8409\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.6093 - acc: 0.8583 - val_loss: 0.5111 - val_acc: 0.8674\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.4398 - acc: 0.8794 - val_loss: 0.3955 - val_acc: 0.8872\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.3560 - acc: 0.8942 - val_loss: 0.3344 - val_acc: 0.8973\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.3063 - acc: 0.9039 - val_loss: 0.3079 - val_acc: 0.8995\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2739 - acc: 0.9109 - val_loss: 0.2897 - val_acc: 0.9020\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2489 - acc: 0.9182 - val_loss: 0.2636 - val_acc: 0.9099\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.2309 - acc: 0.9230 - val_loss: 0.2552 - val_acc: 0.9141\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2150 - acc: 0.9284 - val_loss: 0.2392 - val_acc: 0.9170\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2017 - acc: 0.9330 - val_loss: 0.2378 - val_acc: 0.9187\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1909 - acc: 0.9352 - val_loss: 0.2554 - val_acc: 0.9103\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1800 - acc: 0.9400 - val_loss: 0.2275 - val_acc: 0.9171\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1703 - acc: 0.9423 - val_loss: 0.2224 - val_acc: 0.9214\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1611 - acc: 0.9456 - val_loss: 0.2181 - val_acc: 0.9211\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1530 - acc: 0.9488 - val_loss: 0.2192 - val_acc: 0.9229\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1450 - acc: 0.9517 - val_loss: 0.2137 - val_acc: 0.9218\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1371 - acc: 0.9550 - val_loss: 0.2167 - val_acc: 0.9212\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1309 - acc: 0.9562 - val_loss: 0.2193 - val_acc: 0.9215\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1220 - acc: 0.9594 - val_loss: 0.2188 - val_acc: 0.9222\n",
            "1/1 [==============================] - 1s 641ms/step - loss: 0.2419 - acc: 0.9158\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 13s 29ms/step - loss: 1.7573 - acc: 0.6363 - val_loss: 1.2446 - val_acc: 0.7744\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.9476 - acc: 0.7937 - val_loss: 0.7178 - val_acc: 0.8138\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.6071 - acc: 0.8402 - val_loss: 0.5095 - val_acc: 0.8528\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.4499 - acc: 0.8726 - val_loss: 0.4046 - val_acc: 0.8771\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.3635 - acc: 0.8905 - val_loss: 0.3472 - val_acc: 0.8882\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.3123 - acc: 0.9028 - val_loss: 0.3106 - val_acc: 0.8996\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.2775 - acc: 0.9113 - val_loss: 0.2948 - val_acc: 0.8963\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2550 - acc: 0.9152 - val_loss: 0.2711 - val_acc: 0.9080\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.2336 - acc: 0.9221 - val_loss: 0.2647 - val_acc: 0.9080\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.2174 - acc: 0.9275 - val_loss: 0.2495 - val_acc: 0.9133\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2052 - acc: 0.9311 - val_loss: 0.2635 - val_acc: 0.9069\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1937 - acc: 0.9347 - val_loss: 0.2371 - val_acc: 0.9175\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.1822 - acc: 0.9380 - val_loss: 0.2409 - val_acc: 0.9137\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1726 - acc: 0.9408 - val_loss: 0.2327 - val_acc: 0.9167\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1641 - acc: 0.9434 - val_loss: 0.2272 - val_acc: 0.9197\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1560 - acc: 0.9468 - val_loss: 0.2400 - val_acc: 0.9143\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.1479 - acc: 0.9498 - val_loss: 0.2289 - val_acc: 0.9164\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1398 - acc: 0.9517 - val_loss: 0.2471 - val_acc: 0.9129\n",
            "1/1 [==============================] - 1s 632ms/step - loss: 0.2534 - acc: 0.9119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(accuracy)\n",
        "var = np.var(accuracy)\n",
        "print(f\"the mean of 3 runs is {mean}, and the variance is {var}\")\n",
        "\n",
        "plt.boxplot(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "nojo7WnJwWFh",
        "outputId": "bce6ea91-bbcf-488d-b1f8-5751e7ebb5eb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean of 3 runs is 0.9144999782244364, and the variance is 3.3799852880002213e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boxes': [<matplotlib.lines.Line2D at 0x7fd3acf90a90>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7fd3ad11b810>,\n",
              "  <matplotlib.lines.Line2D at 0x7fd3ad11bd50>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7fd3ad123850>],\n",
              " 'means': [],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7fd3ad123310>],\n",
              " 'whiskers': [<matplotlib.lines.Line2D at 0x7fd3acef9110>,\n",
              "  <matplotlib.lines.Line2D at 0x7fd3ad11b2d0>]}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### apply BN after post_activation: BN(g(f(x)))"
      ],
      "metadata": {
        "id": "Utysl_O9weRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "filter=64\n",
        "kernel=3 \n",
        "before_activation_bn = False\n",
        "\n",
        "accuracy = []\n",
        "for i in range(3):\n",
        "    tf.random.set_seed(i + 24)\n",
        "    model = ImageRecognitionCNN(num_classes, \n",
        "                                filter=filter,\n",
        "                                kernel=kernel, \n",
        "                                before_activation_bn=before_activation_bn)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    acc = keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n",
        "\n",
        "    model.compile(optimizer, loss=loss_fn, metrics=[acc])\n",
        "    callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "    history = model.fit(x_train, y_train, epochs=50, batch_size=128,\n",
        "              validation_data=(x_val, y_val),\n",
        "              callbacks=[callback])\n",
        "\n",
        "    _, test_accuracy = model.evaluate(x_test, y_test, batch_size=len(x_test))\n",
        "    accuracy.append(test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d5Ris6Uwmcq",
        "outputId": "f8cd46e7-d1c4-4f56-b9ec-60aca5b7a3a8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "391/391 [==============================] - 13s 28ms/step - loss: 1.6355 - acc: 0.6689 - val_loss: 1.1108 - val_acc: 0.8044\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.8247 - acc: 0.8272 - val_loss: 0.6148 - val_acc: 0.8453\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.5176 - acc: 0.8653 - val_loss: 0.4445 - val_acc: 0.8722\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.3904 - acc: 0.8846 - val_loss: 0.3714 - val_acc: 0.8868\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.3267 - acc: 0.8978 - val_loss: 0.3259 - val_acc: 0.8915\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2883 - acc: 0.9074 - val_loss: 0.2989 - val_acc: 0.8982\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2624 - acc: 0.9120 - val_loss: 0.2755 - val_acc: 0.9042\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.2408 - acc: 0.9178 - val_loss: 0.2646 - val_acc: 0.9072\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2254 - acc: 0.9223 - val_loss: 0.2610 - val_acc: 0.9071\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.2105 - acc: 0.9272 - val_loss: 0.2585 - val_acc: 0.9073\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1973 - acc: 0.9311 - val_loss: 0.2491 - val_acc: 0.9127\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1865 - acc: 0.9357 - val_loss: 0.2498 - val_acc: 0.9087\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.1772 - acc: 0.9381 - val_loss: 0.2461 - val_acc: 0.9141\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1662 - acc: 0.9431 - val_loss: 0.2427 - val_acc: 0.9145\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1579 - acc: 0.9453 - val_loss: 0.2474 - val_acc: 0.9120\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1486 - acc: 0.9483 - val_loss: 0.2442 - val_acc: 0.9153\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 11s 29ms/step - loss: 0.1406 - acc: 0.9519 - val_loss: 0.2510 - val_acc: 0.9121\n",
            "1/1 [==============================] - 1s 619ms/step - loss: 0.2656 - acc: 0.9061\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 12s 28ms/step - loss: 1.7705 - acc: 0.6909 - val_loss: 1.3253 - val_acc: 0.8030\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 1.0015 - acc: 0.8265 - val_loss: 0.7611 - val_acc: 0.8473\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.6051 - acc: 0.8629 - val_loss: 0.4986 - val_acc: 0.8701\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.4383 - acc: 0.8807 - val_loss: 0.4049 - val_acc: 0.8786\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.3573 - acc: 0.8934 - val_loss: 0.3486 - val_acc: 0.8882\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.3146 - acc: 0.9007 - val_loss: 0.3184 - val_acc: 0.8926\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2807 - acc: 0.9099 - val_loss: 0.3072 - val_acc: 0.8927\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.2616 - acc: 0.9132 - val_loss: 0.2908 - val_acc: 0.8999\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2428 - acc: 0.9179 - val_loss: 0.2774 - val_acc: 0.9022\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.2280 - acc: 0.9233 - val_loss: 0.2792 - val_acc: 0.9002\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2149 - acc: 0.9262 - val_loss: 0.2591 - val_acc: 0.9099\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.2037 - acc: 0.9304 - val_loss: 0.2592 - val_acc: 0.9075\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.1926 - acc: 0.9341 - val_loss: 0.2643 - val_acc: 0.9108\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1830 - acc: 0.9363 - val_loss: 0.2534 - val_acc: 0.9121\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1738 - acc: 0.9397 - val_loss: 0.2553 - val_acc: 0.9117\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1663 - acc: 0.9422 - val_loss: 0.2442 - val_acc: 0.9147\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1560 - acc: 0.9464 - val_loss: 0.2474 - val_acc: 0.9124\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1512 - acc: 0.9477 - val_loss: 0.2499 - val_acc: 0.9141\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1431 - acc: 0.9514 - val_loss: 0.2573 - val_acc: 0.9131\n",
            "1/1 [==============================] - 1s 556ms/step - loss: 0.2811 - acc: 0.9038\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 12s 28ms/step - loss: 1.7272 - acc: 0.6555 - val_loss: 1.2305 - val_acc: 0.8148\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.9257 - acc: 0.8358 - val_loss: 0.6933 - val_acc: 0.8514\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.5592 - acc: 0.8703 - val_loss: 0.4781 - val_acc: 0.8720\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.4102 - acc: 0.8877 - val_loss: 0.3881 - val_acc: 0.8829\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.3363 - acc: 0.9002 - val_loss: 0.3400 - val_acc: 0.8881\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2956 - acc: 0.9069 - val_loss: 0.3109 - val_acc: 0.8955\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2653 - acc: 0.9134 - val_loss: 0.2884 - val_acc: 0.9000\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2445 - acc: 0.9182 - val_loss: 0.2700 - val_acc: 0.9083\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.2269 - acc: 0.9233 - val_loss: 0.2625 - val_acc: 0.9095\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2131 - acc: 0.9285 - val_loss: 0.2584 - val_acc: 0.9103\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1996 - acc: 0.9315 - val_loss: 0.2558 - val_acc: 0.9097\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1889 - acc: 0.9346 - val_loss: 0.2537 - val_acc: 0.9126\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1778 - acc: 0.9391 - val_loss: 0.2502 - val_acc: 0.9123\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1686 - acc: 0.9419 - val_loss: 0.2597 - val_acc: 0.9080\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1600 - acc: 0.9447 - val_loss: 0.2566 - val_acc: 0.9099\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1508 - acc: 0.9482 - val_loss: 0.2514 - val_acc: 0.9114\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 0.2805 - acc: 0.9039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(accuracy)\n",
        "var = np.var(accuracy)\n",
        "print(f\"the mean of 3 runs is {mean}, and the variance is {var}\")\n",
        "\n",
        "plt.boxplot(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "kMqU7JkAwrnW",
        "outputId": "a641bd7a-31ea-4d77-e47b-47df27798f0a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean of 3 runs is 0.9046000043551127, and the variance is 1.1266233512527733e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boxes': [<matplotlib.lines.Line2D at 0x7fd3aa6e3d90>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7fd3aa6ec850>,\n",
              "  <matplotlib.lines.Line2D at 0x7fd3aa6ecd90>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7fd3aa6f6890>],\n",
              " 'means': [],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7fd3aa6f6350>],\n",
              " 'whiskers': [<matplotlib.lines.Line2D at 0x7fd3ad048950>,\n",
              "  <matplotlib.lines.Line2D at 0x7fd3aa6ec310>]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}